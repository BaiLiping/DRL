{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence to Sequence with Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import rnn, nn\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(d2l.Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention_cell = d2l.MLPAttention(num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = rnn.LSTM(num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Dense(vocab_size, flatten=False)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_len, *args):\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        # Transpose outputs to (batch_size, seq_len, hidden_size) \n",
    "        return (outputs.swapaxes(0,1), hidden_state, enc_valid_len)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, hidden_state, enc_valid_len = state\n",
    "        X = self.embedding(X).swapaxes(0, 1)\n",
    "        outputs = []\n",
    "        for x in X:\n",
    "            # query shape: (batch_size, 1, hidden_size)\n",
    "            query = hidden_state[0][-1].expand_dims(axis=1)\n",
    "            # context has same shape as query\n",
    "            context = self.attention_cell(\n",
    "                query, enc_outputs, enc_outputs, enc_valid_len)\n",
    "            # concatenate on the feature dimension\n",
    "            x = nd.concat(context, x.expand_dims(axis=1), dim=-1)\n",
    "            # reshape x to (1, batch_size, embed_size+hidden_size)\n",
    "            out, hidden_state = self.rnn(x.swapaxes(0, 1), hidden_state)\n",
    "            outputs.append(out)\n",
    "        outputs = self.dense(nd.concat(*outputs, dim=0))\n",
    "        return outputs.swapaxes(0, 1), [enc_outputs, hidden_state, \n",
    "                                        enc_valid_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 7, 10), 3, (4, 7, 16), 2, (2, 4, 16))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = d2l.Seq2SeqEncoder(vocab_size=10, embed_size=8,\n",
    "                             num_hiddens=16, num_layers=2)\n",
    "encoder.initialize()\n",
    "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, \n",
    "                                  num_hiddens=16, num_layers=2)\n",
    "decoder.initialize()\n",
    "X = nd.zeros((4, 7))\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "out, state = decoder(X, state)\n",
    "out.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 0.115, time 34.2 sec\n",
      "epoch 100, loss 0.067, time 34.6 sec\n",
      "epoch 150, loss 0.043, time 35.4 sec\n",
      "epoch 200, loss 0.032, time 34.6 sec\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_examples, max_len = 64, 1e3, 10\n",
    "lr, num_epochs, ctx = 0.005, 200, d2l.try_gpu()\n",
    "\n",
    "src_vocab, tgt_vocab, train_iter = d2l.load_data_nmt(\n",
    "    batch_size, max_len, num_examples)\n",
    "encoder = d2l.Seq2SeqEncoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(\n",
    "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_ch7(model, train_iter, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go . => va !\n",
      "Wow ! => <unk> !\n",
      "I'm OK . => je vais bien .\n",
      "I won ! => je l'ai emportÃ© !\n"
     ]
    }
   ],
   "source": [
    "for sentence in ['Go .', 'Wow !', \"I'm OK .\", 'I won !']:\n",
    "    print(sentence + ' => ' + d2l.translate_ch7(\n",
    "        model, sentence, src_vocab, tgt_vocab, max_len, ctx))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
