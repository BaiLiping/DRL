{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"DataVisualization.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bTQ-ExnoiAeY","colab_type":"text"},"source":["## TensorBoard for Visualization\n","\n","TensorBoard is a neural network visualization library developed by Google as part of Tensorflow. In the past, people can use TensorBoard in PyTorch via third-party adaptors like tensorboardX. Starting from 1.2.0 (the latest version), **PyTorch officially supports TensorBoard**. We recommend you to use the latest version of PyTorch and use its built-in support of TensorBoard for visualization.\n","\n","This tutorial covers how to use PyTorch's official support of TensorBoard. You can also refer to the [official documentation](https://pytorch.org/docs/stable/tensorboard.html). If you insist on using an older version of PyTorch, try [tensorboardX](https://github.com/lanpa/tensorboardX).\n","\n","Let's take up the same task as defined in Recitation 2. We'll be training a Neural Network to classify if a set of points $(x_1, x_2)$ lie inside a circle of radius $1$ or not. For more details on what the task is, please re-visit Recitation 2.\n"]},{"cell_type":"code","metadata":{"id":"UwK3leNfLxwe","colab_type":"code","colab":{}},"source":["# Install required libraries\n","!pip install torch>=1.2.0 tensorboard future tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vXkLZjiiAec","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WdKH8sD_iAek","colab_type":"text"},"source":["Similar to Recitation 2, we first sample some polar co-ordinates that are randomly distributed within a circle of radius 2 and centered at origin, ie. $(0,0)$."]},{"cell_type":"code","metadata":{"id":"GIvpTW7giAel","colab_type":"code","colab":{}},"source":["import math\n","\n","def sample_points(n):\n","    \"\"\"\n","    :param n: Total number of data-points\n","    :return: A tuple (X,y) where X is a float tensor with shape (n,2)\n","               and y is an interger tensor with shape(n,)\n","    \"\"\"    \n","    radius = torch.rand(n) * 2\n","    angle = torch.rand(n) * 2 * math.pi\n","    x1 = radius * angle.cos()\n","    x2 = radius * angle.sin()\n","    y = radius < 1\n","    x = torch.stack([x1, x2], dim=1)\n","    return x, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JXyeDBkiAeq","colab_type":"code","outputId":"5cac8bca-59fa-4287-c7fd-4e9f4c5266b7","executionInfo":{"status":"ok","timestamp":1568841355900,"user_tz":240,"elapsed":3229,"user":{"displayName":"Liwei Cai","photoUrl":"","userId":"16466533746106471957"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Generating the data\n","\n","X_train, y_train = sample_points(10000)\n","X_val,y_val = sample_points(500)\n","\n","print(X_train.size(), y_train.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([10000, 2]) torch.Size([10000])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IxjmcoMDrojK","colab_type":"code","outputId":"59a6457e-d704-4dd1-dd2e-2dcc249479dc","executionInfo":{"status":"ok","timestamp":1568841355900,"user_tz":240,"elapsed":3227,"user":{"displayName":"Liwei Cai","photoUrl":"","userId":"16466533746106471957"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Build a simple MLP\n","def build_model(dims, activation):\n","  layers = []\n","  for i in range(len(dims) - 1):\n","    layers.append(nn.Linear(dims[i], dims[i + 1]))\n","    if i < len(dims) - 2:\n","      layers.append(activation())\n","  return nn.Sequential(*layers)\n","\n","# Test the function\n","print(build_model([2, 12, 1], nn.Sigmoid))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Linear(in_features=2, out_features=12, bias=True)\n","  (1): Sigmoid()\n","  (2): Linear(in_features=12, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"moSbTVIziAeb","colab_type":"text"},"source":["A SummaryWriter writes all values we want to visualize to a given directory. This line creates a SummaryWriter that creates write event files and saves in the `./runs/example` directory.\n","```python\n","from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter(\"./runs/example\")\n","```\n","You should use different run directories in a common root directory for different runs of your model. TensorBoard looks for runs in the root directory. So for this example, we start the TensorBoard with:\n","\n","```sh\n","tensorboard --logdir=./runs\n","```\n","Then, visit `localhost:6006` with your browser to see the TensorBoard."]},{"cell_type":"markdown","metadata":{"id":"q7l7fn7viAe0","colab_type":"text"},"source":["Each time we add a value, we specify a **tag** and a **step**. Each tag is a string and corresponds to a plot on TensorBoard. The step is an integer (`epoch` in this example) that serves as the X axis on the plot.\n","\n","To plot a single scalar, use [*SummaryWriter.add_scalar()*](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar). To plot multiple scalars on a plot, use [*SummaryWriter.add_scalars()*](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars) and pass in a dict of scalars.\n","\n","Using [*SummaryWriter.add_histogram()*](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_histogram) to plot a histogram of values in a tensor is also useful for understanding the dynamics of the network."]},{"cell_type":"code","metadata":{"id":"6cat4BvXxn3Z","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","\n","def train(model, writer, epochs=1000):\n","  criterion = nn.BCEWithLogitsLoss()\n","  optimizer = torch.optim.Adam(model.parameters())\n","  for epoch in tqdm(range(epochs)):\n","    model.zero_grad()\n","    out = model(X_train).flatten()\n","    loss = criterion(out, y_train.float())\n","    train_loss = loss.item()\n","    train_acc = ((out > 0) == y_train).float().mean().item()\n","    \n","    loss.backward()\n","    # Plot histogram of gradient of all parameters\n","    for name, param in model.named_parameters():\n","      writer.add_histogram('grad_' + name, param.grad.data, epoch)\n","    optimizer.step()\n","    \n","    with torch.no_grad():\n","      out = model(X_val).flatten()\n","      val_loss = criterion(out, y_val.float()).item()\n","      val_acc = ((out > 0) == y_val).float().mean().item()\n","    # Plot loss and accuracy on train and val\n","    writer.add_scalars('loss', {'train': train_loss, 'val': val_loss}, epoch)\n","    writer.add_scalars('acc', {'train': train_acc, 'val': val_acc}, epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HWJ8UNjFiAfA","colab_type":"text"},"source":["## Using Different Activation functions\n","\n","Let's see and understand how each of these activation functions perform.\n","\n","- Sigmoid\n","    * Get values between 0 and 1.\n","    * A Sigmoid layer easily dies or saturates. A value too small kills the gradient flow whereas a value too big saturates the neurons, effectively passing no information through it.\n","    \n","- Tanh\n","    * Outputs values between -1 and 1. Also zero centered and so does not have the problem of all positive/negative gradients.\n","    * Better than Sigmoid but problem of saturation persists.\n","\n","- ReLU\n","    * Converges quickly as is a threshold based activation and does not saturate.\n","    * Neurons die off. Large weight update could set the weights in such a way (they become negative) during backpropagation that they never fire for any data point. Important to set lower learning rates for ReLU.\n","    \n","    \n","**TRY IT OUT**\n","\n","Use all the 3 activation functions. See which performs better and try to find out why. "]},{"cell_type":"code","metadata":{"id":"YXJykUfUiAfU","colab_type":"code","outputId":"92382484-1f24-4ab2-9dbb-55aab719eba2","executionInfo":{"status":"ok","timestamp":1568841398500,"user_tz":240,"elapsed":45823,"user":{"displayName":"Liwei Cai","photoUrl":"","userId":"16466533746106471957"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter(\"./runs/sigmoid\")\n","model = build_model([2, 12, 1], nn.Sigmoid)\n","train(model, writer)\n","\n","writer = SummaryWriter(\"./runs/tanh\")\n","model = build_model([2, 12, 1], nn.Tanh)\n","train(model, writer)\n","\n","writer = SummaryWriter(\"./runs/relu\")\n","model = build_model([2, 12, 1], nn.ReLU)\n","train(model, writer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1000/1000 [00:14<00:00, 70.95it/s]\n","100%|██████████| 1000/1000 [00:14<00:00, 68.54it/s]\n","100%|██████████| 1000/1000 [00:13<00:00, 72.27it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"TZqK0YxbNoZm","colab_type":"text"},"source":["Open TensorBoard and see the result!\n","\n","![TensorBoard: accuracy](tensorboard_acc.png)\n","\n","![TensorBoard: gradient distribution](tensorboard_grad.png)"]}]}